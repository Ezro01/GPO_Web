"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —ç–º–æ—Ü–∏–π –ø–æ –≥–æ–ª–æ—Å—É
"""
import os
import numpy as np
import pandas as pd
import librosa
import soundfile as sf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import json
from tqdm import tqdm

class EmotionClassifier:
    def __init__(
        self,
        sample_rate=22050,
        duration=3,
        n_mfcc=13,
        augmentation_factor=1,
        random_state=42,
    ):
        self.sample_rate = sample_rate
        self.duration = duration
        self.n_mfcc = n_mfcc
        self.augmentation_factor = augmentation_factor
        self.model = None
        self.label_encoder = LabelEncoder()
        self._rng = np.random.default_rng(random_state)

    def _pad_or_trim(self, y):
        """–ü—Ä–∏–≤–æ–¥–∏—Ç –∞—É–¥–∏–æ –∫ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –¥–ª–∏–Ω–µ."""
        target_len = self.sample_rate * self.duration
        if len(y) < target_len:
            y = np.pad(y, (0, target_len - len(y)), mode='constant')
        elif len(y) > target_len:
            y = y[:target_len]
        return y

    def _extract_features_from_waveform(self, y, sr):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ –∞—É–¥–∏–æ."""
        y = self._pad_or_trim(y)

        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=self.n_mfcc)
        chroma = librosa.feature.chroma_stft(y=y, sr=sr)
        mel = librosa.feature.melspectrogram(y=y, sr=sr)
        contrast = librosa.feature.spectral_contrast(y=y, sr=sr)
        tonnetz = librosa.feature.tonnetz(y=y, sr=sr)

        return np.hstack([
            np.mean(mfccs, axis=1),
            np.mean(chroma, axis=1),
            np.mean(mel, axis=1),
            np.mean(contrast, axis=1),
            np.mean(tonnetz, axis=1)
        ])

    def _augment_waveforms(self, y, sr):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∞—É–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ—Ä—Å–∏–∏ –∞—É–¥–∏–æ."""
        if self.augmentation_factor <= 1:
            return []

        def add_noise(signal, scale=0.02):
            noise = self._rng.normal(0, 1, len(signal))
            return signal + scale * np.std(signal) * noise

        def pitch_shift(signal, steps):
            return librosa.effects.pitch_shift(signal, sr=sr, n_steps=steps)

        def time_stretch(signal, rate):
            return librosa.effects.time_stretch(signal, rate=rate)

        def shift(signal, max_fraction=0.2):
            shift_amt = int(self._rng.uniform(-max_fraction, max_fraction) * len(signal))
            return np.roll(signal, shift_amt)

        def gain(signal, db):
            factor = np.power(10, db / 20)
            return signal * factor

        augmenters = [
            lambda sig: add_noise(sig, scale=self._rng.uniform(0.01, 0.05)),
            lambda sig: pitch_shift(sig, steps=self._rng.uniform(-3, 3)),
            lambda sig: time_stretch(sig, rate=self._rng.uniform(0.8, 1.25)),
            lambda sig: shift(sig, max_fraction=0.2),
            lambda sig: gain(sig, db=self._rng.uniform(-6, 6)),
        ]

        augmented = []
        target_len = self.sample_rate * self.duration
        needed = self.augmentation_factor - 1

        for i in range(needed):
            aug_fn = augmenters[i % len(augmenters)]
            try:
                aug = aug_fn(y)
                aug = self._pad_or_trim(aug)
                augmented.append(aug)
            except Exception:
                continue

        normalized = []
        for a in augmented:
            if len(a) != target_len:
                a = self._pad_or_trim(a)
            normalized.append(a)

        return normalized

    def extract_features(self, audio_path):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞."""
        try:
            y, sr = librosa.load(audio_path, sr=self.sample_rate, duration=self.duration)
            return self._extract_features_from_waveform(y, sr)
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {audio_path}: {e}")
            return None

    def prepare_data(self, csv_path, audio_dir):
        """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
        print("\n" + "=" * 60)
        print("–ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–•")
        print("=" * 60)
        
        df = pd.read_csv(csv_path)
        print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –∑–∞–ø–∏—Å–µ–π –∏–∑ CSV")
        
        X = []
        y = []
        failed = 0
        
        print("\n–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ –∞—É–¥–∏–æ —Ñ–∞–π–ª–æ–≤...")
        if self.augmentation_factor > 1:
            print(f"‚öôÔ∏è  –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è: {self.augmentation_factor}x –Ω–∞ –∫–∞–∂–¥—ã–π —Ñ–∞–π–ª")

        for idx, row in tqdm(df.iterrows(), total=len(df), desc="–û–±—Ä–∞–±–æ—Ç–∫–∞"):
            audio_path = os.path.join(audio_dir, row['path'])
            if os.path.exists(audio_path):
                try:
                    y_wave, sr = librosa.load(audio_path, sr=self.sample_rate, duration=self.duration)
                    base_features = self._extract_features_from_waveform(y_wave, sr)
                    if base_features is not None:
                        X.append(base_features)
                        y.append(row['emotion'])

                        for aug_wave in self._augment_waveforms(y_wave, sr):
                            aug_features = self._extract_features_from_waveform(aug_wave, sr)
                            if aug_features is not None:
                                X.append(aug_features)
                                y.append(row['emotion'])
                    else:
                        failed += 1
                except Exception as e:
                    print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {audio_path}: {e}")
                    failed += 1
            else:
                failed += 1

        print(f"\n‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(X)} —Ñ–∞–π–ª–æ–≤")
        print(f"‚ùå –ü—Ä–æ–ø—É—â–µ–Ω–æ: {failed} —Ñ–∞–π–ª–æ–≤")
        
        X = np.array(X)
        y = np.array(y)
        
        # –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç–æ–∫
        y_encoded = self.label_encoder.fit_transform(y)
        
        print(f"\n–ö–ª–∞—Å—Å—ã —ç–º–æ—Ü–∏–π: {self.label_encoder.classes_}")
        print(f"–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {X.shape[1]}")
        
        return X, y_encoded, y
    
    def build_model(self, input_dim, num_classes):
        """–°–æ–∑–¥–∞–µ—Ç –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å"""
        print("\n" + "=" * 60)
        print("–°–û–ó–î–ê–ù–ò–ï –ú–û–î–ï–õ–ò")
        print("=" * 60)
        
        model = keras.Sequential([
            layers.Dense(256, activation='relu', input_shape=(input_dim,)),
            layers.Dropout(0.3),
            layers.Dense(128, activation='relu'),
            layers.Dropout(0.3),
            layers.Dense(64, activation='relu'),
            layers.Dropout(0.2),
            layers.Dense(num_classes, activation='softmax')
        ])
        
        model.compile(
            optimizer='adam',
            loss='sparse_categorical_crossentropy',
            metrics=['accuracy']
        )
        
        print("\n–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏:")
        model.summary()
        
        return model
    
    def train(self, X, y, epochs=1000, batch_size=32, validation_split=0.2):
        """–û–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å"""
        print("\n" + "=" * 60)
        print("–û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò")
        print("=" * 60)
        
        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train –∏ validation
        X_train, X_val, y_train, y_val = train_test_split(
            X, y, test_size=validation_split, random_state=42, stratify=y
        )
        
        print(f"–û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞: {len(X_train)}")
        print(f"–í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞: {len(X_val)}")
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
        num_classes = len(self.label_encoder.classes_)
        self.model = self.build_model(X.shape[1], num_classes)
        
        # Callbacks
        early_stopping = keras.callbacks.EarlyStopping(
            monitor='val_loss',
            patience=50,
            restore_best_weights=True
        )
        
        reduce_lr = keras.callbacks.ReduceLROnPlateau(
            monitor='val_loss',
            factor=0.5,
            patience=50,
            min_lr=0.0001
        )
        
        # –û–±—É—á–µ–Ω–∏–µ
        print("\nüöÄ –ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è...\n")
        history = self.model.fit(
            X_train, y_train,
            validation_data=(X_val, y_val),
            epochs=epochs,
            batch_size=batch_size,
            callbacks=[early_stopping, reduce_lr],
            verbose=1
        )
        
        # –í—ã–≤–æ–¥ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫
        print("\n" + "=" * 80)
        print(" " * 25 + "–°–¢–ê–¢–ò–°–¢–ò–ö–ò –û–ë–£–ß–ï–ù–ò–Ø")
        print("=" * 80)
        
        final_train_acc = history.history['accuracy'][-1]
        final_val_acc = history.history['val_accuracy'][-1]
        best_val_acc = max(history.history['val_accuracy'])
        best_epoch = history.history['val_accuracy'].index(best_val_acc) + 1
        best_train_acc = max(history.history['accuracy'])
        
        print(f"\n{'='*80}")
        print(f"{'üìä –û–°–ù–û–í–ù–´–ï –ú–ï–¢–†–ò–ö–ò':^80}")
        print(f"{'='*80}")
        print(f"{'–ú–µ—Ç—Ä–∏–∫–∞':<40} {'–ó–Ω–∞—á–µ–Ω–∏–µ':>20} {'–ü—Ä–æ—Ü–µ–Ω—Ç':>20}")
        print(f"{'-'*80}")
        print(f"{'–¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ –æ–±—É—á–µ–Ω–∏–∏ (—Ñ–∏–Ω–∞–ª—å–Ω–∞—è)':<40} {final_train_acc:>20.4f} {final_train_acc*100:>19.2f}%")
        print(f"{'–¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ –æ–±—É—á–µ–Ω–∏–∏ (–ª—É—á—à–∞—è)':<40} {best_train_acc:>20.4f} {best_train_acc*100:>19.2f}%")
        print(f"{'–¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (—Ñ–∏–Ω–∞–ª—å–Ω–∞—è)':<40} {final_val_acc:>20.4f} {final_val_acc*100:>19.2f}%")
        print(f"{'–¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (–ª—É—á—à–∞—è)':<40} {best_val_acc:>20.4f} {best_val_acc*100:>19.2f}%")
        print(f"{'–õ—É—á—à–∞—è —ç–ø–æ—Ö–∞':<40} {best_epoch:>20}")
        
        print(f"\n{'='*80}")
        print(f"{'üìà –ò–°–¢–û–†–ò–Ø –û–ë–£–ß–ï–ù–ò–Ø':^80}")
        print(f"{'='*80}")
        print(f"{'–ü–∞—Ä–∞–º–µ—Ç—Ä':<40} {'–ó–Ω–∞—á–µ–Ω–∏–µ':>40}")
        print(f"{'-'*80}")
        print(f"{'–í—Å–µ–≥–æ —ç–ø–æ—Ö –æ–±—É—á–µ–Ω–æ':<40} {len(history.history['loss']):>40}")
        print(f"{'–§–∏–Ω–∞–ª—å–Ω–∞—è loss (–æ–±—É—á–µ–Ω–∏–µ)':<40} {history.history['loss'][-1]:>40.4f}")
        print(f"{'–§–∏–Ω–∞–ª—å–Ω–∞—è loss (–≤–∞–ª–∏–¥–∞—Ü–∏—è)':<40} {history.history['val_loss'][-1]:>40.4f}")
        print(f"{'–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è loss (–≤–∞–ª–∏–¥–∞—Ü–∏—è)':<40} {min(history.history['val_loss']):>40.4f}")
        print(f"{'–≠–ø–æ—Ö–∞ —Å –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π loss':<40} {history.history['val_loss'].index(min(history.history['val_loss'])) + 1:>40}")
        
        # –î–∏–Ω–∞–º–∏–∫–∞ –æ–±—É—á–µ–Ω–∏—è
        print(f"\n{'='*80}")
        print(f"{'üìâ –î–ò–ù–ê–ú–ò–ö–ê –û–ë–£–ß–ï–ù–ò–Ø (–ø–µ—Ä–≤—ã–µ 5 –∏ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 5 —ç–ø–æ—Ö)':^80}")
        print(f"{'='*80}")
        print(f"{'–≠–ø–æ—Ö–∞':<8} {'Train Acc':<12} {'Val Acc':<12} {'Train Loss':<12} {'Val Loss':<12}")
        print(f"{'-'*80}")
        
        epochs_list = list(range(1, len(history.history['loss']) + 1))
        for i in [0, 1, 2, 3, 4]:
            if i < len(epochs_list):
                ep = epochs_list[i]
                print(f"{ep:<8} {history.history['accuracy'][i]:<12.4f} {history.history['val_accuracy'][i]:<12.4f} "
                      f"{history.history['loss'][i]:<12.4f} {history.history['val_loss'][i]:<12.4f}")
        
        if len(epochs_list) > 5:
            print(f"{'...':^80}")
            for i in range(-5, 0):
                ep = epochs_list[i]
                idx = len(epochs_list) + i
                print(f"{ep:<8} {history.history['accuracy'][idx]:<12.4f} {history.history['val_accuracy'][idx]:<12.4f} "
                      f"{history.history['loss'][idx]:<12.4f} {history.history['val_loss'][idx]:<12.4f}")
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        print(f"\n{'='*80}")
        print(f"{'üìã –î–ï–¢–ê–õ–¨–ù–´–ô –û–¢–ß–ï–¢ –ü–û –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–ò':^80}")
        print(f"{'='*80}")
        y_pred = self.model.predict(X_val, verbose=0)
        y_pred_classes = np.argmax(y_pred, axis=1)
        
        report = classification_report(
            y_val, 
            y_pred_classes, 
            target_names=self.label_encoder.classes_,
            output_dict=True
        )
        
        print(f"\n{'–ö–ª–∞—Å—Å':<20} {'Precision':<15} {'Recall':<15} {'F1-score':<15} {'Support':<15}")
        print(f"{'-'*80}")
        for emotion in self.label_encoder.classes_:
            if emotion in report:
                print(f"{emotion:<20} {report[emotion]['precision']:<15.4f} {report[emotion]['recall']:<15.4f} "
                      f"{report[emotion]['f1-score']:<15.4f} {report[emotion]['support']:<15}")
        
        print(f"{'-'*80}")
        print(f"{'–°—Ä–µ–¥–Ω–µ–µ (macro)':<20} {report['macro avg']['precision']:<15.4f} {report['macro avg']['recall']:<15.4f} "
              f"{report['macro avg']['f1-score']:<15.4f} {report['macro avg']['support']:<15}")
        print(f"{'–°—Ä–µ–¥–Ω–µ–µ (weighted)':<20} {report['weighted avg']['precision']:<15.4f} {report['weighted avg']['recall']:<15.4f} "
              f"{report['weighted avg']['f1-score']:<15.4f} {report['weighted avg']['support']:<15}")
        
        # –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫
        print(f"\n{'='*80}")
        print(f"{'üî¢ –ú–ê–¢–†–ò–¶–ê –û–®–ò–ë–û–ö (CONFUSION MATRIX)':^80}")
        print(f"{'='*80}")
        cm = confusion_matrix(y_val, y_pred_classes)
        print(f"\n{'–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ ‚Üí':<15}", end="")
        for emotion in self.label_encoder.classes_:
            print(f"{emotion[:8]:<10}", end="")
        print()
        print("-" * (15 + 10 * len(self.label_encoder.classes_)))
        for i, emotion in enumerate(self.label_encoder.classes_):
            print(f"{'–†–µ–∞–ª—å–Ω–æ ‚Üì':<5} {emotion[:8]:<6}", end="")
            for j in range(len(self.label_encoder.classes_)):
                print(f"{cm[i][j]:<10}", end="")
            print()
        
        print(f"\n{'='*80}")
        print(f"{'‚úÖ –û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û –£–°–ü–ï–®–ù–û':^80}")
        print(f"{'='*80}\n")
        
        return history
    
    def save_model(self, model_path='emotion_model.h5', encoder_path='label_encoder.json'):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –º–æ–¥–µ–ª—å –∏ —ç–Ω–∫–æ–¥–µ—Ä"""
        if self.model is not None:
            self.model.save(model_path)
            print(f"\n‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {model_path}")
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —ç–Ω–∫–æ–¥–µ—Ä–∞
            encoder_dict = {
                'classes': self.label_encoder.classes_.tolist()
            }
            with open(encoder_path, 'w', encoding='utf-8') as f:
                json.dump(encoder_dict, f, ensure_ascii=False, indent=2)
            print(f"‚úÖ –≠–Ω–∫–æ–¥–µ—Ä —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {encoder_path}")
    
    def load_model(self, model_path='emotion_model.h5', encoder_path='label_encoder.json'):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å –∏ —ç–Ω–∫–æ–¥–µ—Ä"""
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"–§–∞–π–ª –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {model_path}")
        if not os.path.exists(encoder_path):
            raise FileNotFoundError(f"–§–∞–π–ª —ç–Ω–∫–æ–¥–µ—Ä–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω: {encoder_path}")
        
        self.model = keras.models.load_model(model_path)
        
        with open(encoder_path, 'r', encoding='utf-8') as f:
            encoder_dict = json.load(f)
        self.label_encoder.classes_ = np.array(encoder_dict['classes'])
        
        print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {model_path}")
        print(f"‚úÖ –≠–Ω–∫–æ–¥–µ—Ä –∑–∞–≥—Ä—É–∂–µ–Ω: {encoder_path}")
        print(f"‚úÖ –ö–ª–∞—Å—Å—ã: {', '.join(self.label_encoder.classes_)}")
    
    def predict(self, audio_path):
        """–ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç —ç–º–æ—Ü–∏—é –¥–ª—è –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞"""
        features = self.extract_features(audio_path)
        if features is None:
            return None
        
        features = features.reshape(1, -1)
        prediction = self.model.predict(features, verbose=0)
        predicted_class_idx = np.argmax(prediction[0])
        predicted_emotion = self.label_encoder.classes_[predicted_class_idx]
        confidence = prediction[0][predicted_class_idx]
        
        # –í—Å–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
        probabilities = {
            emotion: float(prob) 
            for emotion, prob in zip(self.label_encoder.classes_, prediction[0])
        }
        
        return {
            'emotion': predicted_emotion,
            'confidence': float(confidence),
            'probabilities': probabilities
        }


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
    print("\n" + "=" * 60)
    print("–û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–ò –≠–ú–û–¶–ò–ô")
    print("=" * 60)
    
    classifier = EmotionClassifier(augmentation_factor=10)
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    X, y_encoded, y_labels = classifier.prepare_data('train.csv', 'train')
    
    # –û–±—É—á–µ–Ω–∏–µ
    history = classifier.train(X, y_encoded, epochs=1000, batch_size=32)
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    classifier.save_model()
    
    print("\n" + "=" * 60)
    print("–û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û")
    print("=" * 60)


if __name__ == "__main__":
    main()
